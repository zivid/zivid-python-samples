# python-samples

[![Build Status][ci-badge]][ci-url]

This repository contains **Python** code samples for **Zivid**.

## Samples list

There are two main categories of samples: **camera** and **applications**. The samples in the **camera** category focus only on how to use the camera. The samples in the **applications** category use the output generated by the camera, such as the 3D point cloud, a 2D image or other data from the camera. These samples shows how the data from the camera can be used.

- **camera**
  - **basic** ([quick tutorial][QuickCaptureTutorial-url] / [complete tutorial][CompleteCaptureTutorial-url])
    - [**capture**][capture-url] - This example shows how to acquire images from the Zivid camera.
    - [**capture_2d**][capture_2d-url] - This example shows how to acquire only 2D images from the Zivid camera.
    - [**capture_assistant**][capture_assistant-url] - This example shows how to use Capture Assistant to acquire HDR images from the Zivid camera.
    - [**capture_from_file**][capture_from_file-url] - This example shows how to acquire HDR images from file. This example can be used without access to a physical camera.
    - [**capture_hdr**][capture_hdr-url] - This example shows how to acquire HDR images from the Zivid camera.
    - [**capture_hdr_complete_settings**][capture_hdr_complete_settings-url] - This example shows how to acquire HDR images from the Zivid camera and configure all settings.
  - **info_util_other**
    - [**print_version_info**][print_version_info-url] - This example shows how to print version info about connected Zivid cameras and the installed Zivid SDK.

- **applications**
  - **basic**
    - [**capture_hdr_loop**][capture_hdr_loop-url] - This example shows how to acquire HDR images from the Zivid camera in a loop (while actively changing some HDR settings).
    - [**capture_hdr_separate_frames**][capture_hdr_separate_frames-url] - Capture several individual frames and merge them into one HDR
    - **visualization**
      - [**read_zdf_vis_3d**][read_zdf_vis_3d-url] - This example shows how to read a PCL point cloud and visualize it.
    - **file_formats**
      - [**convert_zdf**][convert_zdf-url] - This example shows how to convert from ZDF to your preferred format (.ply, .csv, .txt, .png, .jpg, .bmp, .tiff).
      - [**read_iterate_zdf**][read_iterate_zdf-url] - This example shows how to import and display a Zivid point cloud from a .ZDF file.
  - **advanced**
    - [**hand_eye_calibration**][hand_eye_calibration-url]
      - [**calibrate_eye_to_hand**][calibrate_eye_to_hand-url] - This samples shows how to perform a complete Hand to Eye calibration
      - [**utilize_eye_in_hand_calibration**][utilize_eye_in_hand_calibration-url] - Transform a 3D point from camera frame to robot base frame using hand-eye calibration matrix.
      - [**pose_conversions**][pose_conversions-url] - Convert to/from Transformation Matrix (Rotation Matrix + Translation Vector)
      - **universal_robots_hand_eye_calibration**
        - [**universal_robots_perform_hand_eye_calibration**][ur_perform_hand_eye_calibration-url] - Generate dataset and perform hand-eye calibration on generated dataset.
        - **Dependencies:**
          - [OpenCV](https://opencv.org/) version 4.0.1 or newer.
          - [RTDE][rtde_guide-url] version 1.0 or newer.
          - [Scipy](https://www.scipy.org/) version 1.4.0 or newer.
    - [**downsample**][downsample-url]  - This example shows how to import a Zivid point cloud from a .ZDF file and downsample it.
      - **Dependencies:**
        - [Eigen](http://eigen.tuxfamily.org/) version 3.3.7 or newer
    - [**create_depth_map**][create_depth_map-url] - Import a ZDF point cloud and convert it to OpenCV format, then extract and visualize depth map.
    - [**mask_point_cloud**][mask_point_cloud-url] - Import ZDF point cloud, apply a binary mask, and visualize it.
      - **Dependencies:**
        - [OpenCV](https://opencv.org/) version 4.0.1 or newer
    - [**gamma_correction**][gamma_correction-url] - Modify gamma of the 2D image.
      - **Dependencies:**
        - [OpenCV](https://opencv.org/) version 4.0.1 or newer
    - [**color_balance**][color_balance-url] - Balance color for RGB image.

## Instructions

1. [**Install Zivid Software**](https://www.zivid.com/downloads).
Note: The version tested with Zivid cameras is 1.8.1.

2. [**Install Zivid Python**](https://github.com/zivid/zivid-python).

3. [**Download Zivid Sample Data**](https://zivid.atlassian.net/wiki/spaces/ZividKB/pages/450363393/Sample+Data).

4. [Optional] Launch the Python IDE of your choice. Read our instructions on [**setting up Python**](https://zivid.atlassian.net/wiki/spaces/ZividKB/pages/427556/Setting+up+Python).

5. Install the runtime requirements using IDE or command line:

       pip install -r requirements.txt

6. Add the directory `source` to PYTHONPATH. Navigate to the root of the repository and run:

    - PowerShell: `$env:PYTHONPATH=$env:PYTHONPATH + ";$PWD\source"`
    - cmd: `set PYTHONPATH="$PYTHONPATH;$PWD\source"`
    - bash: `export PYTHONPATH="$PYTHONPATH:$PWD/source"`

7. Open and run one of the samples.

## Support
If you need assistance with using Zivid cameras, visit our Knowledge Base at [https://help.zivid.com/](https://help.zivid.com/) or contact us at [customersuccess@zivid.com](mailto:customersuccess@zivid.com).

## Licence
Zivid Samples are distributed under the [BSD license](source/LICENSE).

[ci-badge]: https://img.shields.io/azure-devops/build/zivid-devops/701a6042-3865-4412-9f7f-78b846c1a406/3
[ci-url]: https://dev.azure.com/zivid-devops/python-samples/_build/latest?definitionId=3&branchName=master
[QuickCaptureTutorial-url]: source/camera/basic/QuickCaptureTutorial.md
[CompleteCaptureTutorial-url]: source/camera/basic/CaptureTutorial.md
[capture-url]: source/camera/basic/capture.py
[capture_2d-url]: source/camera/basic/capture_2d.py
[capture_assistant-url]: source/camera/basic/capture_assistant.py
[capture_from_file-url]: source/camera/basic/capture_from_file.py
[capture_hdr-url]: source/camera/basic/capture_hdr.py
[capture_hdr_complete_settings-url]: source/camera/basic/capture_hdr_complete_settings.py
[print_version_info-url]: source/camera/info_util_other/print_version_info.py
[capture_hdr_loop-url]: source/applications/basic/capture_hdr_loop.py
[capture_hdr_separate_frames-url]: source/applications/basic/capture_hdr_separate_frames.py
[read_zdf_vis_3d-url]: source/applications/basic/visualization/read_zdf_vis_3d.py
[convert_zdf-url]: source/applications/basic/file_formats/convert_zdf.py
[read_iterate_zdf-url]: source/applications/basic/file_formats/read_iterate_zdf.py
[hand_eye_calibration-url]: source/applications/advanced/hand_eye_calibration
[calibrate_eye_to_hand-url]: source/applications/advanced/hand_eye_calibration/calibrate_eye_to_hand.py
[utilize_eye_in_hand_calibration-url]: source/applications/advanced/hand_eye_calibration/utilize_eye_in_hand_calibration.py
[pose_conversions-url]: source/applications/advanced/hand_eye_calibration/pose_conversions.py
[ur_perform_hand_eye_calibration-url]: source/applications/advanced/hand_eye_calibration/ur_hand_eye_calibration/universal_robots_perform_hand_eye_calibration.py
[rtde_guide-url]: https://www.universal-robots.com/how-tos-and-faqs/how-to/ur-how-tos/real-time-data-exchange-rtde-guide-22229/
[downsample-url]: source/applications/advanced/downsample.py
[create_depth_map-url]: source/applications/advanced/create_depth_map.py
[gamma_correction-url]: source/applications/advanced/gamma_correction.py
[color_balance-url]: source/applications/advanced/color_balance.py
